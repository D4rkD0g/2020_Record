λCUDA
## CUDA

#### 1. CUDA 组成  
cuda core，或者称为sp，是主要的运算单元  
在硬件上比SP更大的运算单位称为SM (Streaming Multiprocessors)，一个SM是由多个SP加上其他的资源组成的，实际上SM才更像是一个具有完整功能的CORE。因为SM可以调度并发射指令到运算单元内。  
[](https://pic2.zhimg.com/80/v2-8c9abad3321a3b4775fe490a3fef2a52_1440w.jpg)  

最基本的程序并行结构称为thread，这是程序员可以控制的最细粒度的并行单位。每一个thread在运算单元上就对应一个sp。多个thread组合起来称为一个block，数量是程序员可以设定的。在同一个block内的thread之间可以相互通信，因为他们可以共用同一个SM内的shared memory(共享储内存)，每一个thread还拥有各自独占的register(寄存器)和local memory(本地储存器)，这些thread以32个为单位组成一个单元，称作warps。warp中所有线程并行的执行相同的指令。
Grid 对应于GPU，一个GPU就是一个Grid  
Block对应与MultiProcessors这个物理实体  
Thread对应于MultiProcessors下面的core这个物理实体，thread 运行在core上  


#### 2. CUDA SIMT

CUDA采用Single Instruction Multiple Thread（SIMT）的架构来管理和执行thread  

下面是一个采用SIMD进行运算的例子：  
```c
void add(uint32_t *a, uint32_t *b, uint32_t *c, int n) {
  for(int i=0; i<n; i+=4) {
    //compute c[i], c[i+1], c[i+2], c[i+3]
    uint32x4_t a4 = vld1q_u32(a+i);
    uint32x4_t b4 = vld1q_u32(b+i);
    uint32x4_t c4 = vaddq_u32(a4,b4);
    vst1q_u32(c+i,c4);
  }
}
```

下面是一个SIMT的例子：  
```c
__global__ void add(float *a, float *b, float *c) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  a[i]=b[i]+c[i]; //no loop!
}
```

#### 3. GPU架构  

- Fermi  
- Kepler，相较于Fermi更快，效率更高，性能更好。  
    Dynamic Parallelism： GPU动态的启动新的Grid，kernel直接启动另外的kernel，而不需要CPU  
    Hyper-Q：为GPU和CPU提供了32个工作队列  

#### 4. 其他  
cuda加速库：OpenACC
cuBLAS 则是一个处理矩阵运算的函数库  
cuDNN 是一个基于深度网路神经设计的GPU加速函数库  

多GPU并行计算之数据并行：需要频繁更新  
多GPU并行计算之模型并行：通信量巨大  